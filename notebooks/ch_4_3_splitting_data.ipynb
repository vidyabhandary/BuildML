{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data\n",
    "\n",
    "In the [previous notebook](ch4_dataset_exploration.ipynb), we explored a dataset. Next, we will separate it into a training and test split. Separating a dataset into splits is crucial to validate the performance of a model. By using only a subset of data to train a model, you can use unseen data to produce an estimate of how your model would perform in practice.\n",
    "\n",
    "In this notebook, I will demonstrate a few ways to do just that using the `writers` Stack Overflow dataset. First, we load and format data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import umap\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_editor.ch4_data_processing import format_raw_df, get_random_train_test_split, get_vectorized_inputs_and_label, get_split_by_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../raw_data/writers.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "df = format_raw_df(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Split\n",
    "The simplest way to generate a test set is to randomly split data between a training set and a test set. This is what we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43106 entries, 1 to 53935\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Unnamed: 0                 43106 non-null  int64  \n",
      " 1   AcceptedAnswerId           5191 non-null   float64\n",
      " 2   AnswerCount                43106 non-null  int32  \n",
      " 3   Body                       43106 non-null  object \n",
      " 4   ClosedDate                 1344 non-null   object \n",
      " 5   CommentCount               43106 non-null  int64  \n",
      " 6   CommunityOwnedDate         190 non-null    object \n",
      " 7   ContentLicense             43106 non-null  object \n",
      " 8   CreationDate               43106 non-null  object \n",
      " 9   FavoriteCount              4107 non-null   float64\n",
      " 10  Id                         43106 non-null  int32  \n",
      " 11  LastActivityDate           43106 non-null  object \n",
      " 12  LastEditDate               14862 non-null  object \n",
      " 13  LastEditorDisplayName      988 non-null    object \n",
      " 14  LastEditorUserId           14048 non-null  float64\n",
      " 15  OwnerDisplayName           3463 non-null   object \n",
      " 16  OwnerUserId                43106 non-null  int32  \n",
      " 17  ParentId                   32851 non-null  float64\n",
      " 18  PostTypeId                 43106 non-null  int32  \n",
      " 19  Score                      43106 non-null  int64  \n",
      " 20  Tags                       10255 non-null  object \n",
      " 21  Title                      10255 non-null  object \n",
      " 22  ViewCount                  10255 non-null  float64\n",
      " 23  body_text                  43106 non-null  object \n",
      " 24  is_question                43106 non-null  bool   \n",
      " 25  Id_question                32851 non-null  float64\n",
      " 26  Title_question             32851 non-null  object \n",
      " 27  body_text_question         32851 non-null  object \n",
      " 28  Score_question             32851 non-null  float64\n",
      " 29  AcceptedAnswerId_question  18149 non-null  float64\n",
      "dtypes: bool(1), float64(8), int32(4), int64(3), object(14)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    32851\n",
       "1    10255\n",
       "Name: PostTypeId, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PostTypeId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    32851\n",
       "True     10255\n",
       "Name: is_question, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_question'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rand, test_df_rand = get_random_train_test_split(df[df['is_question']], test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7178 questions in training, 3077 in test.\n",
      "3791 different owners in the training set\n",
      "1869 different owners in the testing set\n",
      "733 owners appear in both sets\n"
     ]
    }
   ],
   "source": [
    "print('%s questions in training, %s in test.' %(len(train_df_rand), len(test_df_rand)))\n",
    "train_owners = set(train_df_rand['OwnerUserId'].values)\n",
    "test_owners  = set(test_df_rand['OwnerUserId'].values)\n",
    "\n",
    "print('%s different owners in the training set' % len(train_owners))\n",
    "print('%s different owners in the testing set' % len(test_owners))\n",
    "print('%s owners appear in both sets' % len(train_owners.intersection(test_owners)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Split\n",
    "\n",
    "Some authors may be more skilled at asking questions then others. If an author appears in both the training and the test set, a model could successfully predict the performance of their questions simply by successfully identifying the author. Note that simply removing the AuthorId from the set of features does not fully solve this problem, as the formulation of a question may be author specific (especially if some authors include their signature).\n",
    "\n",
    "To make sure we are accurately judging question quality, we would want to make sure that a given author only appears in either the training set or the validation set. This guarantee that a model will not be able to leverage information to identify a given author and use it to predict more easily.\n",
    "\n",
    "To remove this potential source of bias, let's split data by author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_author, test_author = get_split_by_author(df[df['is_question']], test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7310 questions in training, 2945 in test.\n",
      "3448 different owners in the training set\n",
      "1479 different owners in the testing set\n",
      "0 owners appear in both sets\n"
     ]
    }
   ],
   "source": [
    "print('%s questions in training, %s in test.' % (len(train_author),len(test_author)))\n",
    "train_owners = set(train_author['OwnerUserId'].values)\n",
    "test_owners = set(test_author['OwnerUserId'].values)\n",
    "print('%s different owners in the training set' % len(train_owners))\n",
    "print('%s different owners in the testing set' % len(test_owners))\n",
    "print('%s owners appear in both sets' % len(train_owners.intersection(test_owners)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward we will use the author split, but there are other methods of splitting data for other types of data. For example, we may want to use a time-based split in order to see whether training on questions written in a given period can produce a model that works well on questions from a more recent period. Please refer to the book for more information on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
