{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained image models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penultimate layer thus contains a representation of the image that is sufficient to classify which object it contains, which makes it a useful representation for other tasks. Extracting this representation layer proves to work extremely well at generating meaningful vectors for images. This requires no custom work other than loading the pretrained model.\n",
    "\n",
    "\n",
    "The most useful representation is usually located just before the classification layer, since that is the representation that needs to summarize the image best for the classifier to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function that loads images from a folder and transforms them into semantically meaningful\n",
    "vectors for downstream analysis, using a pretrained network available in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(image_paths):\n",
    "    '''\n",
    "    Takes in an array of image paths\n",
    "    Returns pretrained features for each image\n",
    "    :param image_paths: array of image paths\n",
    "    :return: array of last-layer activations,\n",
    "    and mapping from array_index to file_path\n",
    "    '''\n",
    "    \n",
    "    images = np.zeros(shape=(len(image_paths), 224, 224, 3))\n",
    "    \n",
    "    # loading a pretrained model\n",
    "    pretrained_vgg16 = VGG16(weights='imagenet', include_top=True)\n",
    "    \n",
    "    # Using only the penultimate layer, to leverage learned features\n",
    "    model = Model(inputs=pretrained_vgg16.input, outputs=pretrained_vgg16.get_layer('fc2').output)\n",
    "    \n",
    "    # We load all our dataset in memory (works for small datasets)\n",
    "    \n",
    "    for i, f in enumerate(image_paths):\n",
    "        img = image.load_img(f, target_size=(224, 224))\n",
    "        x_raw = image.img_to_array(img)\n",
    "        x_expand = np.expand_dims(x_raw, axis=0)\n",
    "        images[i, :, :, :] = x_expand\n",
    "        \n",
    "    # Once we've loaded all our images, we pass them to our model\n",
    "    inputs = preprocess_input(images)\n",
    "    images_features = model.predict(inputs)\n",
    "    return images_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
